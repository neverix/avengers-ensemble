     1) Решение - это CatBoost. На вход получает предсказания языковых моделей и признаки NLP:
       - язык label
       - тип label(ORG, LOC ...)
       - кол-во label в тексте
       - кол-во слов в тексте 
       - кол-во слов в вопросе
       - кол-во символов в label
       Код CatBoost + предсказания трансформеров: https://yadi.sk/d/g1_zfTCDx_Bj3A
     2) Данные переведены на английский с помощью API перевода документов Goolge Translate.
        Перевод ускорен с помощью прокси сети Tor. Исходный код: translate.py
     3) Модели в итоговом решении:
       - vicgalle/xlm-roberta-large-xnli-anli: многоязыковая модель, сама по себе 86%.
         На вход получает предобработанные русские данные. Обучалась на задаче бинарной классификации правильного ответа.
         Данные сбалансированы. Тренировалась на полных данных в течение 3 эпох.
         Обучалась на Кристофари. Код: XLM.ipynb. 
       - T5. Модель работает на англоязычных данных. Обучалась на переведенном train.
         Обучение происходило на Colab и Google Compute Engine (trial version) с сохранением в Google Cloud Storage.
         Использовались модели 3B и 11B. Обучались на протяжении 1000-3000 итераций.
         Код для обработки данных: data.py, add_ren.py, write_zero.py.
         Код для обучения 3B: 3B_trainer.ipynb, 3B_eval.ipynb; 11B: 11.ipynb.
